{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPOBwsAXI+TR5beXRK7nRmU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amk735/DS340W-project-flower-image-classification/blob/main/FlowerTransferLearning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras import optimizers, callbacks\n",
        "import tensorflow.keras.backend as K\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense"
      ],
      "metadata": {
        "id": "j7QrdQi3PhfD"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
        "assert len(physical_devices) > 0, \"Not enough GPU hardware devices available\"\n",
        "config = tf.config.experimental.set_memory_growth(physical_devices[0], True)"
      ],
      "metadata": {
        "id": "2dDrESIaPrul"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gpus = tf.config.experimental.list_physical_devices('GPU') \n",
        "for gpu in gpus: \n",
        "    tf.config.experimental.set_memory_growth(gpu, True)"
      ],
      "metadata": {
        "id": "2sc9F7CePubx"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "qqUARSJHP07O"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_width = 224\n",
        "image_height = 224\n",
        "num_classes = 5\n",
        "histories = []"
      ],
      "metadata": {
        "id": "gWQTuvqAP3S8"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images_dir = \"flowers-subset/\"\n",
        "train_data_dir = images_dir + \"train/\"\n",
        "val_data_dir = images_dir + \"val/\"\n",
        "test_data_dir = images_dir + \"test/\""
      ],
      "metadata": {
        "id": "vNpg1YBwP5xj"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images_dir = \"flowers-subset/\"\n",
        "flowers_complete = \"flowers-complete/\"\n",
        "train_data_dir = images_dir + \"train/\"\n",
        "val_data_dir = flowers_complete\n",
        "test_data_dir = flowers_complete #+ \"test/\""
      ],
      "metadata": {
        "id": "FWxok5XFP64m"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_dir = \"checkpoints/\"\n",
        "checkpoint_name = checkpoint_dir + \"flora-transferLearning-{val_loss:.4f}-{val_accuracy:.4f}.hdf5\"\n",
        "if not os.path.exists(checkpoint_dir):\n",
        "    os.makedirs(checkpoint_dir)"
      ],
      "metadata": {
        "id": "sst31yDUP8j8"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_callbacks():\n",
        "    return [\n",
        "        callbacks.EarlyStopping(monitor=\"val_accuracy\", patience=10, verbose=1),\n",
        "\n",
        "        callbacks.ModelCheckpoint(checkpoint_name, monitor=\"val_accuracy\", \n",
        "                                  verbose=1, save_best_only=True),\n",
        "    ]\n",
        "\n",
        "my_callbacks = create_callbacks()"
      ],
      "metadata": {
        "id": "kDdYntZtP_Xl"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_callbacks = create_callbacks()\n"
      ],
      "metadata": {
        "id": "n559Np1PQAbW"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\n",
        "\n",
        "base_model = MobileNetV2(input_shape=(image_height, image_width, 3), \n",
        "                       include_top=False, weights=\"imagenet\", \n",
        "                       pooling=None)"
      ],
      "metadata": {
        "id": "YLRkptSkQAZd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a77dd72e-769a-47fb-ae02-903bc2f09128"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
            "9406464/9406464 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "                    rotation_range=40,\n",
        "                    width_shift_range=0.2,\n",
        "                    height_shift_range=0.2,\n",
        "                    shear_range=0.2,\n",
        "                    zoom_range=0.2,\n",
        "                    channel_shift_range=0.2,\n",
        "                    horizontal_flip=True,\n",
        "                    fill_mode=\"nearest\",\n",
        "                    preprocessing_function=preprocess_input)\n",
        "\n",
        "val_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
        "\n",
        "test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)"
      ],
      "metadata": {
        "id": "Kybb4WRkQAXG"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "                    train_data_dir,\n",
        "                    target_size=(image_width, image_height),\n",
        "                    batch_size=batch_size,\n",
        "                    class_mode=\"categorical\",\n",
        "                    shuffle=True)\n",
        "\n",
        "val_generator = val_datagen.flow_from_directory(\n",
        "                    val_data_dir,\n",
        "                    target_size=(image_width, image_height),\n",
        "                    batch_size=batch_size,\n",
        "                    class_mode=\"categorical\",\n",
        "                    shuffle=False)\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "                    test_data_dir,\n",
        "                    target_size=(image_width, image_height),\n",
        "                    batch_size=batch_size,\n",
        "                    class_mode=\"categorical\",\n",
        "                    shuffle=False)"
      ],
      "metadata": {
        "id": "H9eYwRIqQAUI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "outputId": "9682f99c-21e0-4668-a996-d7b757c85057"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-c60e29cda6c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m train_generator = train_datagen.flow_from_directory(\n\u001b[0m\u001b[1;32m      4\u001b[0m                     \u001b[0mtrain_data_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                     \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_width\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_height\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/preprocessing/image.py\u001b[0m in \u001b[0;36mflow_from_directory\u001b[0;34m(self, directory, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio)\u001b[0m\n\u001b[1;32m   1646\u001b[0m                 \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0my\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0ma\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0marray\u001b[0m \u001b[0mof\u001b[0m \u001b[0mcorresponding\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1647\u001b[0m         \"\"\"\n\u001b[0;32m-> 1648\u001b[0;31m         return DirectoryIterator(\n\u001b[0m\u001b[1;32m   1649\u001b[0m             \u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1650\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/preprocessing/image.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio, dtype)\u001b[0m\n\u001b[1;32m    561\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m             \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 563\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0msubdir\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    564\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m                     \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'flowers-subset/train/'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import regularizers\n",
        "\n",
        "top_model = Sequential()\n",
        "top_model.add(base_model)\n",
        "top_model.add(GlobalAveragePooling2D())\n",
        "top_model.add(Dropout(0.7))\n",
        "top_model.add(Dense(num_classes, kernel_regularizer=regularizers.l2(0.01)))\n",
        "top_model.add(Activation(\"softmax\"))"
      ],
      "metadata": {
        "id": "WfqasXEdQARy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import regularizers\n",
        "\n",
        "model = Sequential()\n",
        "model.add(base_model)\n",
        "model.add(Conv2D(64, (3, 3), input_shape=(image_height, image_width, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "#b\n",
        "model.add(Conv2D(32, (1, 1)))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
        "model.add(Dense(64))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes, kernel_regularizer=regularizers.l2(0.01)))\n",
        "model.add(Activation(\"softmax\"))"
      ],
      "metadata": {
        "id": "wZOMqLVUQAPp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "top_model.compile(loss=\"categorical_crossentropy\",\n",
        "                  optimizer=optimizers.Adam(lr=1e-4),\n",
        "                  metrics=[\"accuracy\"])    "
      ],
      "metadata": {
        "id": "FaB0AUJwQANs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "histories.append(top_model.fit(train_generator, \n",
        "                              steps_per_epoch=len(train_generator),\n",
        "                              epochs=60,\n",
        "                              callbacks=my_callbacks,\n",
        "                              validation_data=val_generator,\n",
        "                              validation_steps=len(val_generator),\n",
        "                              workers=8))"
      ],
      "metadata": {
        "id": "UBd67G2JQAKk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate on the best model"
      ],
      "metadata": {
        "id": "92wbb9-zQRMl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "model_saved_name = \"\"\n",
        "\n",
        "best_model = load_model(checkpoint_dir + \"flora-transferLearning-0.3959-0.8959.hdf5\")"
      ],
      "metadata": {
        "id": "axh8VU7AQAH4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_model.evaluate_generator(test_generator, steps=len(test_generator))\n"
      ],
      "metadata": {
        "id": "MwXAICWxQVXb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_generator.reset()\n",
        "probabilities = best_model.predict_generator(test_generator, steps=len(test_generator))\n",
        "predicted_labels = np.argmax(probabilities, axis=-1)"
      ],
      "metadata": {
        "id": "99kyk31TQVSo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_labels = test_generator.classes\n"
      ],
      "metadata": {
        "id": "c2jn-6w3QVQz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "conf = metrics.confusion_matrix(target_labels, predicted_labels)"
      ],
      "metadata": {
        "id": "3ldxnlUPQVOT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "\n",
        "def plot_confusion_matrix(conf, labels, figsize=(8, 8)):\n",
        "    fig = plt.figure(figsize=figsize)\n",
        "    heatmap = sns.heatmap(conf, annot=True, fmt=\"d\")\n",
        "    heatmap.xaxis.set_ticklabels(labels, rotation=45, ha=\"right\", fontsize=12)\n",
        "    heatmap.yaxis.set_ticklabels(labels, rotation=0, ha=\"right\", fontsize=12)\n",
        "    plt.xlabel(\"Predicted label\", fontsize=12)\n",
        "    plt.ylabel(\"True label\", fontsize=12)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "qJy2C7GSQVMI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = [\"\"] * num_classes\n",
        "for k, v in test_generator.class_indices.items():\n",
        "    labels[v] = k"
      ],
      "metadata": {
        "id": "GnlY7lFPQVLD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_confusion_matrix(conf, labels, figsize=(14, 14))\n"
      ],
      "metadata": {
        "id": "QES7k_M7QVG0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(metrics.classification_report(target_labels, predicted_labels, target_names=labels))\n"
      ],
      "metadata": {
        "id": "KbsytYagQVEd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Find for which images the predicted class is wrong\n",
        "wrong_images = np.where(predicted_labels != target_labels)[0]\n",
        "\n",
        "# For every prediction, find the largest probability value;\n",
        "# this is the probability of the winning class for this image\n",
        "probs_max = np.max(probabilities, axis=-1)\n",
        "\n",
        "# Sort the probabilities from the wrong images from low to high\n",
        "idx = np.argsort(probs_max[wrong_images])\n",
        "\n",
        "# Reverse the order (high to low), and keep the 5 highest ones\n",
        "idx = idx[::-1][:5]\n",
        "\n",
        "# Get the indices of the images with the worst predictions\n",
        "worst_predictions = wrong_images[idx]\n",
        "\n",
        "index2class = {v:k for k,v in test_generator.class_indices.items()}\n",
        "\n",
        "for i in worst_predictions:\n",
        "    print(\"%s was predicted as '%s' %.4f\\n\" % (\n",
        "        test_generator.filenames[i],\n",
        "        index2class[predicted_labels[i]],\n",
        "        probs_max[i]\n",
        "    ))"
      ],
      "metadata": {
        "id": "PNSgyVpJQVB1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing import image\n",
        "img = image.load_img(test_data_dir + test_generator.filenames[worst_predictions[0]])\n",
        "plt.imshow(img)"
      ],
      "metadata": {
        "id": "icE7sFuYQAAj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Export to Core ML"
      ],
      "metadata": {
        "id": "CkK-0OwCQrNf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import coremltools as ct\n",
        "import os\n",
        "from tensorflow.keras.models import load_model"
      ],
      "metadata": {
        "id": "yjnqhvM_P_0e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_dir = \"ava/\"\n",
        "labels = []\n",
        "checkpoint_dir = \"checkpoints/\"\n",
        "best_model = tensorflow.keras.load_model(checkpoint_dir + \"multisnacks-1.6708-0.4054.hdf5\")"
      ],
      "metadata": {
        "id": "aTWKEG2JQtLA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in os.listdir(label_dir):\n",
        "    if i != '.DS_Store' and i != '._.DS_Store':\n",
        "        labels.append(i)"
      ],
      "metadata": {
        "id": "ErpK6rJ6QtI9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "coreml_model = ct.convert(\n",
        "    best_model,\n",
        "    input_names=[\"image\"],\n",
        "    image_input_names=\"image\",\n",
        "    output_names=\"labelProbability\",\n",
        "    predicted_feature_name=\"label\",\n",
        "    red_bias=-1,\n",
        "    green_bias=-1,\n",
        "    blue_bias=-1,\n",
        "    image_scale=2/255.0,\n",
        "    class_labels=labels)"
      ],
      "metadata": {
        "id": "xQycTvjmQtGK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "coreml_model.author = \"Joshua Ball\"\n",
        "coreml_model.short_description = \"Image classifier\"\n",
        "\n",
        "coreml_model.input_description[\"image\"] = \"Input image\"\n",
        "coreml_model.output_description[\"labelProbability\"]= \"Prediction probabilities\"\n",
        "coreml_model.output_description[\"label\"]= \"Class label of top prediction\""
      ],
      "metadata": {
        "id": "BW5n0tp0QtDj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "coreml_model.save(\"MultiSnacks.mlmodel\")\n"
      ],
      "metadata": {
        "id": "pfmBoiWHQtBe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "m = ct.models.MLModel(\"MultiSnacks.mlmodel\")\n"
      ],
      "metadata": {
        "id": "YZshL1Q7Q3I4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import PIL.Image"
      ],
      "metadata": {
        "id": "WqCnHKPrQ3EL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Height = 224  # use the correct input image height\n",
        "Width = 224  # use the correct input image width"
      ],
      "metadata": {
        "id": "sFQ0aWm8Q29W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_image(path, resize_to=None):\n",
        "    # resize_to: (Width, Height)\n",
        "    img = PIL.Image.open(path)\n",
        "    if resize_to is not None:\n",
        "        img = img.resize(resize_to, PIL.Image.ANTIALIAS)\n",
        "    img_np = np.array(img).astype(np.float32)\n",
        "    return img_np, img"
      ],
      "metadata": {
        "id": "ImIc_ZkLQ263"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_, img = load_image('ava/Ripe/focused_184465770-stock-photo-whole-ripe-avocado.jpg', resize_to=(Width, Height))\n",
        "out_dict = m.predict({'image': img})"
      ],
      "metadata": {
        "id": "ezNBvnuuQ8jG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from skimage import io\n",
        "import matplotlib.pyplot as plt\n",
        "image = io.imread('a.jpg')\n",
        "\n",
        "_ = plt.hist(image.ravel(), bins = 256, color = 'orange', )\n",
        "_ = plt.hist(image[:, :, 0].ravel(), bins = 256, color = 'red', alpha = 0.5)\n",
        "_ = plt.hist(image[:, :, 1].ravel(), bins = 256, color = 'Green', alpha = 0.5)\n",
        "_ = plt.hist(image[:, :, 2].ravel(), bins = 256, color = 'Blue', alpha = 0.5)\n",
        "_ = plt.xlabel('Intensity Value')\n",
        "_ = plt.ylabel('Count')\n",
        "_ = plt.legend(['Total', 'Red_Channel', 'Green_Channel', 'Blue_Channel'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9vfOiE4TQ8aE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from mpl_toolkits.axes_grid1 import ImageGrid\n",
        "fig = plt.figure(figsize=(14., 14.))\n",
        "grid = ImageGrid(fig, 111,  # similar to subplot(111)\n",
        "                 nrows_ncols=(1, 5),  # creates 2x2 grid of axes\n",
        "                 axes_pad=0.0,  # pad between axes in inch.\n",
        "                 )\n",
        "\n",
        "image_data = [io.imread('a.jpg'), io.imread('b.jpg'),io.imread('c.jpg'),io.imread('d.jpg'),io.imread('e.jpg')]\n",
        "for ax, im in zip(grid, image_data):\n",
        "    # Iterating over the grid returns the Axes.\n",
        "    ax.imshow(im,interpolation='nearest') \n",
        "    ax.set_axis_off()\n",
        "\n",
        "    plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2L43ivjzQ23v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize=(10,10))\n",
        "ax = fig.add_subplot(2, 2, 1)\n",
        "imgplot = plt.imshow(io.imread('a.jpg'))\n",
        "ax.set_title('Rose')\n",
        "#plt.colorbar(ticks=[0.1, 0.3, 0.5, 0.7],  orientation='horizontal')\n",
        "imgplot.set_clim(0.0, 0.7)\n",
        "\n",
        "ax = fig.add_subplot(2, 2, 2)\n",
        "imgplot = plt.imshow(io.imread('b.jpg'))\n",
        "imgplot.set_clim(0.0, 0.7)\n",
        "ax.set_title('Dandelion')\n",
        "#plt.colorbar(ticks=[0.1, 0.3, 0.5, 0.7], orientation='horizontal')\n",
        "\n",
        "ax = fig.add_subplot(2, 2, 3)\n",
        "imgplot = plt.imshow(io.imread('c.jpg'))\n",
        "imgplot.set_clim(0.0, 0.7)\n",
        "ax.set_title('Dandelion')\n",
        "#plt.colorbar(ticks=[0.1, 0.3, 0.5, 0.7], orientation='horizontal')\n",
        "\n",
        "ax = fig.add_subplot(2, 2, 4)\n",
        "imgplot = plt.imshow(io.imread('d.jpg'))\n",
        "imgplot.set_clim(0.0, 0.7)\n",
        "ax.set_title('Sunflower')\n",
        "#plt.colorbar(ticks=[0.1, 0.3, 0.5, 0.7], orientation='horizontal')\n",
        "\n",
        "ax = fig.add_subplot(1, 2, 1)\n",
        "imgplot = plt.imshow(io.imread('e.jpg'))\n",
        "imgplot.set_clim(0.0, 0.7)\n",
        "ax.set_title('Tulip')\n",
        "#plt.colorbar(ticks=[0.1, 0.3, 0.5, 0.7], orientation='horizontal')"
      ],
      "metadata": {
        "id": "yJRhNPeoRCcS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}